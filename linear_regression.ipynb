{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SkLearn version is 0.23.2\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "# To save dict\n",
    "import pickle\n",
    "# Dataset\n",
    "import sklearn\n",
    "# function to shuffle dataset and divide into test and train set\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Model functions:\n",
    "#    reg = LinearRegression().fit(x_train, y_train)                Fits the model to (x_train, y_train)\n",
    "#    reg.score(x_train, y_train), reg.score(x_test, y_test)        Get R^2 of the model\n",
    "#    reg.coef_, reg.intercept_                                     Get coefficients\n",
    "#    reg.predict(x_test)                                           Predict results from model\n",
    "print('SkLearn version is {}'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "h_price = pd.read_csv(\"King_County_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric\n",
    "Use __MAPE__ (Mean average percentage error) as metric, because we have regression!\\\n",
    "$mape = \\overline{ape} \\text{  with  } ape=\\frac{y - \\hat{y}}{y}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAPE mean absolute percentage error\n",
    "def mape(a,b):\n",
    "    \"\"\" calculate MAPE, input (y_true, y_pred)\"\"\"\n",
    "    mask = a != 0 # use mask to prevent dividing by zero\n",
    "    return (np.fabs(a-b)/a)[mask].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate all R$^2$\n",
    "Get R$^2$ for all numerical values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 for feature m2_living is 0.49\n",
      "R^2 for feature grade is 0.45\n",
      "R^2 for feature m2_above is 0.37\n",
      "R^2 for feature m2_living15 is 0.34\n",
      "R^2 for feature bathrooms is 0.28\n",
      "R^2 for feature bedrooms is 0.10\n",
      "R^2 for feature lat is 0.09\n",
      "R^2 for feature floors is 0.07\n",
      "R^2 for feature m2_lot is 0.01\n",
      "R^2 for feature m2_lot15 is 0.01\n",
      "R^2 for feature yr_built is 0.00\n",
      "R^2 for feature zipcode is 0.00\n",
      "R^2 for feature condition is 0.00\n",
      "R^2 for feature long is 0.00\n",
      "R^2 for feature date_m is 0.00\n"
     ]
    }
   ],
   "source": [
    "l = []\n",
    "# get result\n",
    "y = h_price.price\n",
    "# for given features\n",
    "for feature in ['bedrooms', 'bathrooms', 'm2_living',\n",
    "                'm2_lot', 'floors', 'condition', 'grade',\n",
    "                'm2_above', 'yr_built', 'zipcode', 'lat',\n",
    "                'long', 'm2_living15', 'm2_lot15', 'date_m'\n",
    "                ]:\n",
    "    X = h_price[feature].to_numpy().reshape(y.shape[0], 1)\n",
    "    reg = LinearRegression().fit(X, y)\n",
    "    l.append([feature, reg.score(X, y)])\n",
    "# sort and print all R2\n",
    "l = sorted(l,key=lambda x: x[1], reverse=True)\n",
    "for i in l:\n",
    "    print('R^2 for feature {} is {:.2f}'.format(i[0], i[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* m2_living, grade, m2_above, m2_living15, bathrooms = __big corr__\n",
    "* bedrooms, lat, floors = __low corr__\n",
    "* zipcode, condition, date_m test with dummies (also grade because it's exponential)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy test\n",
    "Do R$^2$ test with dummies!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 for feature grade is 0.52\n",
      "R^2 for feature zipcode is 0.41\n",
      "R^2 for feature view is 0.17\n",
      "R^2 for feature yr_renovated is 0.03\n",
      "R^2 for feature condition is 0.01\n",
      "R^2 for feature date_m is 0.00\n"
     ]
    }
   ],
   "source": [
    "l = []\n",
    "# get result\n",
    "y = h_price.price\n",
    "# for given features\n",
    "for feature in ['zipcode', 'condition', 'date_m', 'grade', 'view', 'yr_renovated']:\n",
    "    X = pd.get_dummies(h_price[feature], drop_first='True')\n",
    "    reg = LinearRegression().fit(X, y)\n",
    "    l.append([feature, reg.score(X, y)])\n",
    "# sort and print results\n",
    "l = sorted(l,key=lambda x: x[1], reverse=True)\n",
    "for i in l:\n",
    "    print('R^2 for feature {} is {:.2f}'.format(i[0], i[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* grade correlates better as dummy, because it's not linear\n",
    "* zipcode also very good correlation\n",
    "* view correlation not bad\n",
    "* condition, date_m, yr_renovated no correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to preprocess data\n",
    "Create train and test sets, that are standard scaled!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a library with all dummies, in case you only get one example\n",
    "all_dummies = {}\n",
    "for i in ['zipcode', 'condition', 'date_m', 'grade', 'view', 'yr_renovated']:\n",
    "    tmp = pd.get_dummies(h_price[i], prefix=i)\n",
    "    all_dummies[i] = tmp.columns.values\n",
    "# save dict to\n",
    "with open('dummies.pkl', 'wb') as f:\n",
    "    pickle.dump(all_dummies, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_sets(features, features_dummies, dataFrame):\n",
    "    ''' input list of features: list of strings\n",
    "        input list of dummy features: list of strings\n",
    "        input dataframe\n",
    "        res: feature of interest'''\n",
    "    # load dict\n",
    "    with open('dummies.pkl', 'rb') as f:\n",
    "        all_dummies = pickle.load(f)\n",
    "    ## Add dummies to features / data frame\n",
    "    copy = dataFrame.copy()\n",
    "    # Reset index to concat\n",
    "    copy = copy.reset_index(drop=True)\n",
    "    for feat_dum in features_dummies:\n",
    "        df = pd.get_dummies(copy[feat_dum], prefix=feat_dum)\n",
    "        # Add all missing dummy values\n",
    "        dummies = all_dummies[feat_dum]\n",
    "        # initializing dummies with zeros\n",
    "        df_all = pd.DataFrame(0, index=np.arange(df.shape[0]), columns = dummies)\n",
    "        # Add all existing ones in correct order -> loop over full one\n",
    "        for feat in df.columns.values:\n",
    "            df_all[feat] = df[feat]\n",
    "        #df.drop(df.columns[len(df.columns)-1], axis=1, inplace=True)\n",
    "        features = features + list(df_all.columns.values)\n",
    "        copy = pd.concat([copy, df_all], axis=1, sort=False)\n",
    "\n",
    "    X = copy[features].values\n",
    "    \n",
    "    # reshape array to nFeatures, m\n",
    "    if len(X.shape) == 1:\n",
    "        X = X.reshape(X.shape[0], 1)\n",
    "    #print(X.shape)\n",
    "\n",
    "    y = dataFrame.price.values\n",
    "    y = y.reshape(y.shape[0], 1)\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=True)\n",
    "    \n",
    "    # Scale data\n",
    "    scaler = StandardScaler()\n",
    "    # fit scaler to training data\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intuitive Model\n",
    "* use all values from above with good R$^2$!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = ['m2_living', 'm2_above', 'bathrooms']\n",
    "cat_features = ['grade', 'zipcode', 'view']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = get_train_test_sets(num_features, cat_features, h_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create model and fit to training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "linReg = LinearRegression().fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mape for train set: 17.8%\n",
      "Mape for test set:  18.0%\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = linReg.predict(X_train)\n",
    "y_test_pred = linReg.predict(X_test)\n",
    "print('Mape for train set: {:.1f}%'.format(mape(y_train, y_train_pred)*100))\n",
    "print('Mape for test set:  {:.1f}%'.format(mape(y_test, y_test_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* values for train / test set almost the same -> __no overfit__, no regularization needed\n",
    "* test with less values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with less features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = ['m2_living']\n",
    "cat_features = ['grade', 'zipcode', 'view']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update train test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = get_train_test_sets(num_features, cat_features, h_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit pipeline to training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "linReg = LinearRegression().fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mape for train set: 17.7%\n",
      "Mape for test set:  18.0%\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = linReg.predict(X_train)\n",
    "y_test_pred = linReg.predict(X_test)\n",
    "print('Mape for train set: {:.1f}%'.format(mape(y_train, y_train_pred)*100))\n",
    "print('Mape for test set:  {:.1f}%'.format(mape(y_test, y_test_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* features __bathrooms__, __m2_above__ can be __neglected__, result is same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try logarithmic price values\n",
    "Prices are unevenly distributed over large scale, try logarithmic value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mape for train set: 14.7%\n",
      "Mape for test set:  15.0%\n"
     ]
    }
   ],
   "source": [
    "# Features\n",
    "num_features = ['m2_living']\n",
    "cat_features = ['grade', 'zipcode', 'view']\n",
    "\n",
    "# create dataset / scale it\n",
    "X_train, X_test, y_train, y_test = get_train_test_sets(num_features, cat_features, h_price)\n",
    "y_train_log = np.log(y_train)\n",
    "\n",
    "# Create model instance\n",
    "linReg = LinearRegression().fit(X_train, y_train_log)\n",
    "\n",
    "# predict results, turn results back no normal prices\n",
    "y_train_pred = np.exp(linReg.predict(X_train))\n",
    "y_test_pred = np.exp(linReg.predict(X_test))\n",
    "\n",
    "print('Mape for train set: {:.1f}%'.format(mape(y_train, y_train_pred)*100))\n",
    "print('Mape for test set:  {:.1f}%'.format(mape(y_test, y_test_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model accuracy __increased__ by __3%__!!! __Use logarithmic price__!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result\n",
    "Final model gives __accuracy of 15%__.\\\n",
    "The __features__ used are:\n",
    "* m2_living\n",
    "* grade (as dummy)\n",
    "* zipcode (as dummy)\n",
    "* view (as dummy)\n",
    "\n",
    "The __price__ is converted to __logarithmic scale__, so that too high house prices have a lower influence on the total market!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nf] *",
   "language": "python",
   "name": "conda-env-nf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
